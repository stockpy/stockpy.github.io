# choiyoungmin.com/NEWS/dataframe/ í¬ë¡¤ë§ ì½”ë“œ (ê°€ì¥ ê°„ë‹¨í•œ ë°©ë²•)
import pandas as pd
import requests
from io import StringIO

url = "http://choiyoungmin.com/NEWS/dataframe/"

# ë°©ë²• 1: pandas read_html (ê°€ì¥ ì¶”ì²œ)
try:
    tables = pd.read_html(url)
    df = tables[0]  # ì²« ë²ˆì§¸ í…Œì´ë¸” ì„ íƒ
    print("=== í¬ë¡¤ë§ ì„±ê³µ ===")
    print(df)
    df.to_csv("etf_portfolio.csv", index=False)
    print("ğŸ“ etf_portfolio.csv ì €ì¥ ì™„ë£Œ")
    
except Exception as e:
    print(f"pandas ì‹¤íŒ¨: {e}")
    
    # ë°©ë²• 2: requests + BeautifulSoup
    import requests
    from bs4 import BeautifulSoup
    
    headers = {'User-Agent': 'Mozilla/5.0'}
    response = requests.get(url, headers=headers)
    soup = BeautifulSoup(response.text, 'html.parser')
    
    # table ì°¾ê¸°
    table = soup.find('table')
    if table:
        rows = []
        for tr in table.find_all('tr'):
            cells = [td.get_text(strip=True) for td in tr.find_all(['td', 'th'])]
            if cells:  # ë¹ˆ í–‰ ì œì™¸
                rows.append(cells)
        
        df = pd.DataFrame(rows[1:], columns=rows[0])  # ì²«í–‰ í—¤ë”
        print("=== BeautifulSoup ì„±ê³µ ===")
        print(df)
        df.to_csv("etf_portfolio_bs.csv", index=False)
    else:
        print("âŒ í…Œì´ë¸”ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
